{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxf7glFqTAgZ2C9xBcMqZK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MertOguzTasci/Web-Scraping-from-Amazon/blob/main/Web_Scraping_from_Amazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1-It8KeNk7H"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import smtplib\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting to Web through https://httpbin.org/get\n",
        "\n",
        "URL = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "page = requests.get(URL, headers=headers)\n",
        "\n",
        "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
        "\n",
        "title = soup2.find(id='productTitle').get_text()\n",
        "\n",
        "price = soup2.find(id='priceblock_ourprice').get_text()\n",
        "\n",
        "\n",
        "print(title)\n",
        "print(price)"
      ],
      "metadata": {
        "id": "i2CBBow3OE3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price = price.strip()[1:]\n",
        "title = title.strip()"
      ],
      "metadata": {
        "id": "ejc1s5txwJMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Timestamp for your output to track when data was collected\n",
        "\n",
        "import datetime\n",
        "\n",
        "today = datetime.date.today()\n",
        "\n",
        "print(today)"
      ],
      "metadata": {
        "id": "hDKvo5LXy8Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "header = ['Title', 'Price', 'Date']\n",
        "data = [title, price, today]\n",
        "\n",
        "with open('AmazonWebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "KP4dlOdPwi9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('AmazonWebScraperDataset.csv')\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "SoLE37WD_imq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "VujOVezyy9Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all of the above code into one function\n",
        "\n",
        "\n",
        "def check_price():\n",
        "    URL = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n",
        "\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "    page = requests.get(URL, headers=headers)\n",
        "\n",
        "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
        "\n",
        "    title = soup2.find(id='productTitle').get_text()\n",
        "\n",
        "    price = soup2.find(id='priceblock_ourprice').get_text()\n",
        "\n",
        "    price = price.strip()[1:]\n",
        "    title = title.strip()\n",
        "\n",
        "    import datetime\n",
        "\n",
        "    today = datetime.date.today()\n",
        "    \n",
        "    import csv \n",
        "\n",
        "    header = ['Title', 'Price', 'Date']\n",
        "    data = [title, price, today]\n",
        "\n",
        "    with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(data)"
      ],
      "metadata": {
        "id": "Qz0asumS_pmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs check_price after a set time and inputs data into your CSV\n",
        "\n",
        "while(True):\n",
        "    check_price()\n",
        "    time.sleep(86400)"
      ],
      "metadata": {
        "id": "kKyH5OBd_0tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('AmazonWebScraperDataset.csv')\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "RKhJ7fMRBA9u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}